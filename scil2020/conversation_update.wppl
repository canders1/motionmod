// PRINT UTILITIES

//prints json objects
var stringify = function(x){return JSON.stringify(x)}

var printU = function(u){
  console.log("Utterance: "+stringify(u));
}

var printW = function(w){
  console.log("World: "+stringify(w));
}

//prints cost, utterance, evidence pairs
var printOne = function(x,f,c){
  console.log("Cost: "+c)
  console.log("Utterance: "+stringify(x));
  console.log("Evidence: "+stringify(f(x)));
  return
}

// iterates through array and prints all members
var printAll = function(arr,f,c){
  map(function(x){printOne(x,f,c)},arr);
  return
}

//prints information about a generation in a csv-friendly format
var printGeneration = function(genObj){
  var worlds = genObj['speaker_beliefs']['params']['vs'];
  var speaker = normalizeProbs(genObj['speaker_beliefs']['params']['ps']);
  var listener = normalizeProbs(genObj['listener_beliefs']['params']['ps']);
  var prefix = genObj['speaker']+','+genObj['cg_type']+','+genObj['curr_gen']+','+genObj['sampler']['name']+','+genObj['sampled_w']['Index']+','+genObj['selected_u'];
  var belief_pairs = map2(function(x,y){return {speaker: x, listener: y}},speaker,listener);
  if (genObj['cg_type'] == 'shared'){
    var cg = normalizeProbs(genObj['cg']['params']['ps']);
    var cg_worlds = map2(function(x,y){var cgWorld = {cgProb: y}; return Object.assign(cgWorld,x)},worlds,cg);
    var world_pairs = map2(function(x,y){return Object.assign(x,y)},cg_worlds,belief_pairs);
    var print_pairs = map(function(x){console.log(reduce(function(x,y){y+x},prefix,map(function(y){','+y},Object.values(x))))},world_pairs);
  } else {
    var cg_speaker = normalizeProbs(genObj['cg_speaker']['params']['ps']);
    var cg_listener = normalizeProbs(genObj['cg_listener']['params']['ps']);
    var cg_pairs = map2(function(x,y){return {cg_speaker_prob: x, cg_listener_prob: y}},cg_speaker,cg_listener);
    var cg_worlds = map2(function(x,y){return Object.assign(y,x)},worlds,cg_pairs);
    var world_pairs = map2(function(x,y){return Object.assign(x,y)},cg_worlds,belief_pairs);
    var print_pairs = map(function(x){console.log(reduce(function(x,y){y+x},prefix,map(function(y){','+y},Object.values(x))))},world_pairs);
  }
  return
}

// PROB UTILITIES

// argmax

var argmax  = function(arr){
  var init = { currentIndex: arr.length-1, maxIndex: 0, maxValue: arr[0] };
  var a = reduce(function(elt, acc) {
    if (elt > acc.maxValue) {
      return { currentIndex: acc.currentIndex - 1, maxIndex: acc.currentIndex, maxValue: elt };
    }
    else {
       return { currentIndex: acc.currentIndex - 1, maxIndex: acc.maxIndex, maxValue: acc.maxValue };
    }
  }, init, arr);
return a.maxIndex;
};

//min from an array
var arrMin = function(arr){
  return reduce(function(i,acc){return (i < acc)? i : acc},arr[0],arr)
}

// returns the index of the probability in array 1 with the greatest positive difference from array 2 (it is higher in arr 1 than arr 2)
var getHighestDiffProb = function(a1,a2){
  var probDiffs = map2(function(p1,p2){p1-p2},a1,a2);
  var maxDiffIdx = argmax(probDiffs);
  if (sum(probDiffs)/probDiffs.length == probDiffs[maxDiffIdx]){
    return -1;
  } else {
  return maxDiffIdx;
}
}

// returns the index of the probability in Dist. 1 with the greatest positive difference from Dist. 2 (it is higher in Dist. 1 than Dist. 2)
var getHighestDiffDist = function(d1,d2){
  var a1 = normalizeDistProbs(d1);
  var a2 = normalizeDistProbs(d2);
  var probDiffs = map2(function(p1,p2){p1-p2},a1,a2);
  var maxDiffIdx = argmax(probDiffs);
  if (sum(probDiffs)/probDiffs.length == probDiffs[maxDiffIdx]){
    return -1;
  } else {
  return maxDiffIdx;
}
}

// returns a new istribution over worlds weighted by greatest positive probability difference between its arguments
// check the math in the non-negativizing function, I'm not sure it's right
var getDiffDist = function(d1,d2,wset){
  var a1 = normalizeDistProbs(d1);
  var a2 = normalizeDistProbs(d2);
  var probDiffs = map2(function(p1,p2){p1-p2},a1,a2);
  var maxDiffIdx = argmax(probDiffs);
  if (sum(probDiffs)/probDiffs.length == probDiffs[maxDiffIdx]){
    return getWorldDist([wset[0]],[1]);
  } else {
    //check to make sure there are no negative weights:
    var minDiff = arrMin(probDiffs);
    if (minDiff < 0){
      var new_probs = map(function(x){x+(-2*minDiff)},probDiffs);
      return getWorldDist(wset,new_probs);
    } else{
      if (minDiff == 0){
        var new_probs = map(function(x){x+1},probDiffs);
        return getWorldDist(wset,new_probs);
      }
    }
    return getWorldDist(wset,probDiffs);
  }
}

// returns a new distribution dropping all worlds below a certain threshold
var getThreshDist = function(dist,threshold){
  var probs = normalizeProbs(dist['params']['ps']);
  var worlds = dist['params']['vs'];
  var prob_pairs = map2(function(x,y){return {w: x, prob: y}},worlds,probs);
  var above_threshold = filter(function(x){x['prob'] > threshold},prob_pairs);
  var thresh_worlds = map(function(x){return x['w']},above_threshold);
  var thresh_probs = map(function(x){return x['prob']},above_threshold);
  if (thresh_worlds.length == 0){
    return getWorldDist(null_world,[1])
  }
  return getWorldDist(thresh_worlds,thresh_probs);
}

// returns a normalized probability distribution from a webppl distribution object
var normalizeDistProbs = function(dist){
  var prob_weights = dist['params']['ps']
  var prob_sum = sum(prob_weights)
  var probs = map(function(x){x/prob_sum},prob_weights);
  return probs
}

// returns a normalized probability distribution from an array of probability weights
var normalizeProbs = function(weights){
  var prob_sum = sum(weights)
  var probs = map(function(x){x/prob_sum},weights);
  return probs
}

// returns the entropy of a distribution
var findEntropy = function(dist){
  var probs = normalizeDistProbs(dist);
  var filter_probs = filter(function(x){x!=0},probs);
  var log_probs = map(function(x){Math.log2(x)},filter_probs);
  var prob_products = map2(function(x,y){x*y},filter_probs,log_probs);
  var prob_sum = sum(prob_products);
  return -prob_sum
}

// returns the most likely utterance from distribution d
var maxU = function(d){
  var uts = d['params']['dist']
  var keys = Object.keys(uts)
  var us = map(function(k){uts[k]['val']['utterance']},keys)
  var probs = map(function(k){uts[k]['prob']},keys)
  var pairs = map2(function(x,y){return {'utterance' : x, 'prob':y}},us,probs)
  var pMax = reduce(function(x,y){return x['prob']>y['prob']?x:y}, {'utterance' : '', 'prob': 0},pairs)
  return pMax
}

// retrieves the posterior distribution
var getPosteriors = function(interpretation,worlds){
  var int = interpretation['params']['dist']
  var keys = Object.keys(int)
  var probs = map(function(k){int[k]['prob']},keys)
  var ws= map(function(k){int[k]['val']},keys)
  var posts = map(function(x){var idx = ws.indexOf(x); if(idx!= -1){return probs[idx]}else{return 0}},worlds)
  return posts
}

// calculates an posterior distribution over worlds where the prior is updated according to a learning rate
var wUpdate = function(worldPriors,worldPosteriors,lr){
  var updates = map2(function(post,prior){prior+(post*lr)},worldPosteriors,worldPriors)
  var u_sum = sum(updates)
  var updatedWorlds = map(function(u){u/u_sum},updates)
  return updatedWorlds
}

// returns a posterior distribution where world w has all of the probability weight
var getWPosteriorsS = function(w,worlds){
  var posts = map(function(x){if(x==w){1}else{0}},worlds)
  return posts
}

// SAMPLERS

var samplers = {threshold: {name: 'threshold', threshold: 0.35},
weighted: {name: 'weighted'},
difference: {name: 'difference'},
difference_thresh: {name: 'difference_thresh', threshold: 0.35}};

// DISTRIBUTIONS

// default world set
/*var worlds = [
  {"Index": 0, "Major": "German", "School": "University of New Orleans", "Name": "Nancy", "Location Preference": "outdoor"},
  {"Index": 1,"Major": "Astronomy", "School": "Franklin Pierce Law Center", "Name": "Nathan", "Location Preference": "outdoor"}, 
  {"Index": 2,"Major": "German", "School": "State University of New York at Buffalo", "Name": "Daniel", "Location Preference": "outdoor"}, 
  {"Index": 3,"Major": "Hispanic-American Studies", "School": "Franklin Pierce Law Center", "Name": "Gerald", "Location Preference": "indoor"}, 
  /*{"Index": 4, "Major": "Ceramic Engineering", "Company": "Commercial Metals Company","Name": "Nathan", "Location Preference": "outdoor"}, 
  {"Index": 5, "Major": "Adult & Continuing Education", "School": "Canisius College", "Name": "Gary", "Location Preference": "indoor"}, 
  {"Index": 6, "Major": "Veterinary Sciences", "School": "Marymount University", "Name": "Gary", "Location Preference": "outdoor"}, 
  {"Index": 7, "Major": "Electrical Engineering", "School": "University of Dallas", "Name": "Gary", "Location Preference": "outdoor"}, 
  {"Index": 8, "Major": "Astronomy", "School": "Saint Mary's College of California", "Name": "Nathan", "Location Preference": "outdoor"},
  {"Index": 9, "Major": "Social Work & Social Services", "Company": "Commercial Metals Company","Name": "Mary","Location Preference": "outdoor"}
  ]
  */

//balanced world set
var balanced_worlds = [
//{"Index": -1, "Major":undefined, "School": undefined, "Name": undefined, "Location Preference": undefined},
{"Index": 0, "Major": "German", "School": "University of New Orleans", "Name": "Nancy", "Location Preference": "outdoor"},
{"Index": 1, "Major": "German", "School": "University of New Orleans", "Name": "Sally", "Location Preference": "indoor"},
{"Index": 2, "Major": "Astronomy", "School": "University of New Orleans", "Name": "Katie", "Location Preference": "outdoor"},
{"Index": 3, "Major": "Astronomy", "School": "University of New Orleans", "Name": "Ina", "Location Preference": "indoor"},
//{"Index": 4, "Major": "German", "Company": "University of New Orleans", "Name": "Gwen", "Location Preference": "outdoor"},
//{"Index": 5, "Major": "German", "Company": "University of New Orleans", "Name": "Diana", "Location Preference": "indoor"},
//{"Index": 6, "Major": "Astronomy", "Company": "University of New Orleans", "Name": "Felicity", "Location Preference": "outdoor"},
//{"Index": 7, "Major": "Astronomy", "Company": "University of New Orleans", "Name": "Tara", "Location Preference": "indoor"},
]

var null_world = [
{"Index": -1, "Major":undefined, "School": undefined, "Name": undefined, "Location Preference": undefined},
]

// world priors
//var initWorldPriors = [1,1,1,1,1,1,1,1,1,1];

// returns world distribution
var getWorldDist = function(worlds,worldPs) {
	return Categorical({ps: worldPs,vs: worlds})
}

// utterance set
var utterances = [
'They are a student',
//'They work',
//'They are female',
//'They are male',
//'Their name starts with N',
//'Their name is Nancy',
//'Their name is Nathan',
//'Their name is Daniel',
//'Their name is Gary',
//'Their name is Gerald',
//'Their name is Mary',
//'They study German',
//'They study Astronomy',
//'They study Veterinary Sciences',
//'They study Engineering',
//'They study a social science',
'They study a humanity',
'They study a science',
'They like being outdoors',
'They like being indoors',
//'NULL'
]

//utterance priors are even

//returns utterance distribution
var uttPrior = function() {
	return uniformDraw(utterances)
};

// utterance cost function
var utteranceCost = function(utterance) {
  return 0
}

// interpretation function
var get_meaning = function(utterance, world){
  if ((utterance == 'They are a student' && world["School"] != undefined) ||
   (utterance == 'They work' && world["Company"] != undefined) ||
   (utterance == 'They are female' && (world["Name"] == 'Nancy' || world["Name"] == 'Mary')) ||
   (utterance == 'They are male' && (world["Name"] != undefined && world["Name"] != 'Nancy' && world["Name"] != 'Mary')) ||
   (utterance == 'Their name is Nathan' && world["Name"] == 'Nathan') ||
   (utterance == 'They study German' && world["Major"] == 'German') ||
   (utterance == 'They study a science' && (world["Major"] == 'Ceramic Engineering' || world["Major"] == 'Astronomy' || world["Major"] == 'Electrical Engineering' || world["Major"] == "Veterinary Sciences")) ||
   (utterance == 'They study a humanity' && (world["Major"] == "German" || world["Major"] == "Hispanic-American Studies")) ||
   (utterance == 'They study a social science' && (world["Major"] == "Adult & Continuing Education" || world["Major"] == "Social Work & Social Services")) ||
   (utterance == 'Their name starts with N' && (world["Name"] == 'Nathan' || world["Name"] == 'Nancy')) ||
   (utterance == 'They like being outdoors' && world["Location Preference"] == "outdoor") ||
   (utterance == 'They like being indoors' && world["Location Preference"] == "indoor") ||
   (utterance == 'NULL')
   ){
  	return 1
} else {
  return 0
}
}

// RSA MODEL LEVELS

// literal listener: p(w|u) \propto p(u|w)p(w) where p(u|w) is truth value of u in w
var literalListener = function(utterance,worldDist){
   return Infer({model: function(){
   var w = sample(worldDist)
   var meaning = get_meaning(utterance,w)
   condition(meaning)
   return w
   }})
};

// pragmatic speaker: p(u|w) \propto p(w|u)p(u) where p(u) is uniform and p(w|u) is given by literalListener
var pragmaticSpeaker = function(world,worldDist) {
  return Infer({model: function(){
    var utt = uttPrior()
    factor(literalListener(utt,worldDist).score(world))
    return {utterance: utt}
  }})
}

// pragmatic listener: p(w|u) \propto p(u|w)p(w) where p(u|w) is given by pragmaticSpeaker
var pragmaticListener = function(u,worldDist_s,worldDist_l) {
  return Infer({model: function(){
    var w = sample(worldDist_l)
    factor(pragmaticSpeaker(w,worldDist_s).score({utterance:u}))
    return w
  }})
}

// CONTEXT UPDATE 

//initialize distributions
// currently assumes CG is shared and starts out with uniform priors

var init_distributions = function(a_priors,b_priors,world_set,shared){
  var a_beliefs = getWorldDist(world_set,a_priors);
  var b_beliefs = getWorldDist(world_set,b_priors);
  if (shared == 'shared'){
    var cg = getWorldDist(world_set,map(function(x){1},world_set));
    var all_priors = {a_beliefs: a_beliefs, b_beliefs: b_beliefs, cg: cg };
    return all_priors;
  } else{
    var cg_a = getWorldDist(world_set,map(function(x){1},world_set));
    var cg_b = getWorldDist(world_set,map(function(x){1},world_set));
    var all_priors = {a_beliefs: a_beliefs, b_beliefs: b_beliefs, cg_a: cg_a, cg_b: cg_b };
    return all_priors;
  };
}

// simulate a speaker observation by sampling a world
// currently assumes worlds are sampled in proportion to their probability in speaker belief dist.

var sample_world = function(speaker_priors,cg,worlds,sampler){
  if (sampler['name'] == 'weighted') { //sample a world according to its probability in speaker belief dist.
    return sample(speaker_priors);
  }
  if (sampler['name'] == 'difference'){ //sample a world based on the greatest potential probability gain
    var biggest_diff_dist = getDiffDist(speaker_priors,cg,worlds);
    console.log(biggest_diff_dist);
    return sample(biggest_diff_dist);
  }
  if (sampler['name'] == 'difference_thresh'){ //sample a world based on the greatest potential probability gain
    var threshold = sampler.threshold;
    var thresh_dist = getThreshDist(speaker_priors,threshold);
    if (thresh_dist['params']['ps'].length == 1){
      return sample(thresh_dist);
    } else{
      var biggest_diff_dist = getDiffDist(speaker_priors,cg,worlds);
      console.log(biggest_diff_dist);
      return sample(biggest_diff_dist);
    }
  }
  if (sampler['name'] == 'threshold'){ //sample a world according to its probability, omitting low probability worlds
    var threshold = sampler.threshold;
    var thresh_dist = getThreshDist(speaker_priors,threshold);
    return sample(thresh_dist);
  }
}

//speaker calculates which utterance to select

var pick_utterance = function(w,cg){
  var u = maxU(pragmaticSpeaker(w,cg))["utterance"];
  return u
}

// listener interprets utterance (also: speaker models listener interpreting utterance)

var interpret_utterance = function(u,cg){
  var posteriors = getPosteriors(pragmaticListener(u,cg,cg),cg['params']['vs']);
  return posteriors;
}

var interpret_utterance_listener = function(u,cg_l,b_l){
  var posteriors = getPosteriors(pragmaticListener(u,cg_l,b_l),cg_l['params']['vs']);
  return posteriors;
}

// update CG with interpretation of utterance

var update_cg = function(cg,posteriors,lr){
  var cg_priors = cg['params']['ps'];
  var cg_worlds = cg['params']['vs'];
  var updated_weights = map2(function(post,prior){prior+(post*lr)},posteriors,cg_priors);
  var cg_posts = normalizeProbs(updated_weights);
  return getWorldDist(cg_worlds,cg_posts)
}

// update beliefs (this could be combined with update_cg above if the stable form turns out identical)

var update_beliefs = function(beliefs,posteriors,lr){
  var belief_priors = beliefs['params']['ps'];
  var belief_worlds = beliefs['params']['vs'];
  var updated_weights = map2(function(post,prior){prior+(post*lr)},posteriors,belief_priors);
  var belief_posts = normalizeProbs(updated_weights);
  return getWorldDist(belief_worlds,belief_posts)
}

// adjust learning rate based on entropy of belief distribution

var adjustLR = function(beliefs,cg,lr){
  var cg_entropy = findEntropy(cg);
  var belief_entropy = findEntropy(beliefs);
  if (cg_entropy > belief_entropy){
    return 0.1
  } else {
    return 0.35
  }
}

//Simulate a conversation where participants have direct access to a shared Common Ground

var runSharedFixedConversation = function(n_gens,cg,speaker_beliefs,listener_beliefs,sampler,lr_set){
  var genObj = {speaker: "n/a", cg_type: 'shared', curr_gen: 0, speaker_beliefs: speaker_beliefs, sampled_w: {Index: -1}, listener_beliefs: listener_beliefs, cg: cg, sampler: sampler, lr: lr_set['name']};
  printGeneration(genObj);
  return runSharedFixedConversationHelper("a",1,n_gens,cg,speaker_beliefs,listener_beliefs,sampler, lr_set);
}

var runSharedFixedConversationHelper = function(speaker,curr_gen,n_gens,cg,speaker_beliefs,listener_beliefs,sampler,lr_set){
  var lr = lr_set['lr'];
  if (curr_gen == n_gens+1){
    var genObj = {speaker: speaker, cg_type: 'shared', curr_gen: curr_gen, speaker_beliefs: speaker_beliefs, listener_beliefs: listener_beliefs, 
      cg: cg, sampler: sampler, lr: lr_set['name']};
    return genObj;
  } else {
    var world_set = cg['params']['vs'];
    var sampled_w = sample_world(speaker_beliefs,cg,world_set,sampler);
    if (sampled_w["Index"] == -1){
      var selected_u = "NULL";
      var genObj = {speaker: speaker, cg_type: 'shared', curr_gen: curr_gen, speaker_beliefs: speaker_beliefs, listener_beliefs: listener_beliefs, 
      sampled_w: sampled_w, selected_u: selected_u, cg: cg, sampler: sampler, lr: lr_set['name']};
      printGeneration(genObj);
      var next_speaker = (speaker == "a")? "b" : "a";
      runSharedFixedConversationHelper(next_speaker,curr_gen+1,n_gens,cg,listener_beliefs,speaker_beliefs,sampler,lr_set);
    } else {
      var selected_u = pick_utterance(sampled_w,cg);
      var int_posteriors = interpret_utterance(selected_u,cg);
      var new_cg = update_cg(cg,int_posteriors,lr);
      var genObj = {speaker: speaker, cg_type: 'shared', curr_gen: curr_gen, speaker_beliefs: speaker_beliefs, listener_beliefs: listener_beliefs, 
      sampled_w: sampled_w, selected_u: selected_u, cg: new_cg, sampler: sampler, lr: lr_set['name']};
      printGeneration(genObj);
      var next_speaker = (speaker == "a")? "b" : "a";
      runSharedFixedConversationHelper(next_speaker,curr_gen+1,n_gens,new_cg,listener_beliefs,speaker_beliefs,sampler,lr_set);
    }
  }
}

var runApproxFixedConversation = function(n_gens,cg_a,cg_b,a_beliefs,b_beliefs,sampler,lr_set){
  var genObj = {speaker: "n/a", cg_type: 'approx', curr_gen: 0, speaker_beliefs: a_beliefs, sampled_w: {Index: -1}, listener_beliefs: b_beliefs, cg_speaker: cg_a, cg_listener: cg_b, sampler: sampler, lr: lr_set['name']};
  printGeneration(genObj);
  return runApproxFixedConversationHelper("a",1,n_gens,cg_a,cg_b,a_beliefs,b_beliefs,sampler,lr_set);
}

var runApproxFixedConversationHelper = function(speaker,curr_gen,n_gens,cg_speaker,cg_listener,speaker_beliefs,listener_beliefs,sampler,lr_set){
  var lr = lr_set['lr'];
  if (curr_gen == n_gens+1){
    var genObj = {speaker: speaker, cg_type: 'approx', curr_gen: curr_gen, speaker_beliefs: speaker_beliefs, listener_beliefs: listener_beliefs, 
      cg_speaker: cg_speaker, cg_listener: cg_listener, sampler: sampler, lr: lr_set['name']};
    return genObj;
  } else {
    var world_set = speaker_beliefs['params']['vs'];
    var sampled_w = sample_world(speaker_beliefs,cg_speaker,world_set,sampler);
    if (sampled_w["Index"] == -1){
      var selected_u = "NULL";
      var genObj = {speaker: speaker, cg_type: 'approx', curr_gen: curr_gen, speaker_beliefs: speaker_beliefs, listener_beliefs: listener_beliefs, 
      sampled_w: sampled_w, selected_u: selected_u, cg_speaker: cg_speaker, cg_listener: cg_listener, sampler: sampler, lr: lr_set['name']};
      printGeneration(genObj);
      var next_speaker = (speaker == "a")? "b" : "a";
      return runApproxFixedConversationHelper(next_speaker,curr_gen+1,n_gens,cg_listener,cg_speaker,listener_beliefs,speaker_beliefs,sampler,lr_set);
    } else {
      var selected_u = pick_utterance(sampled_w,cg_speaker);
      var int_posteriors_speaker = interpret_utterance(selected_u,cg_speaker); //speaker assumes listener uses CG to interpret
      var int_posteriors_listener = interpret_utterance_listener(selected_u,cg_listener,listener_beliefs); //listener uses their own beliefs as priors, but assumes speaker uses CG to sample
      var new_cg_speaker = update_cg(cg_speaker,int_posteriors_speaker,lr_set['speaker_cg']);
      var new_cg_listener = update_cg(cg_listener,int_posteriors_listener,lr_set['listener_cg']);
      var genObj = {speaker: speaker, cg_type: 'approx', curr_gen: curr_gen, speaker_beliefs: speaker_beliefs, listener_beliefs: listener_beliefs, 
      sampled_w: sampled_w, selected_u: selected_u, cg_speaker: new_cg_speaker, cg_listener: new_cg_listener, sampler: sampler, lr: lr_set['name']};
      printGeneration(genObj);
      var next_speaker = (speaker == "a")? "b" : "a";
      runApproxFixedConversationHelper(next_speaker,curr_gen+1,n_gens,new_cg_listener,new_cg_speaker,listener_beliefs,speaker_beliefs,sampler,lr_set);
    }
  }
}

var runApproxConversation = function(n_gens,cg_a,cg_b,a_beliefs,b_beliefs,sampler,lr_set){
  var genObj = {speaker: "n/a", cg_type: 'approx', curr_gen: 0, speaker_beliefs: a_beliefs, sampled_w: {Index: -1}, listener_beliefs: b_beliefs, cg_speaker: cg_a, cg_listener: cg_b, sampler: sampler, lr: lr_set['name']};
  printGeneration(genObj);
  return runApproxConversationHelper("a",1,n_gens,cg_a,cg_b,a_beliefs,b_beliefs,sampler,lr_set);
}

var runApproxConversationHelper = function(speaker,curr_gen,n_gens,cg_speaker,cg_listener,speaker_beliefs,listener_beliefs,sampler,lr_set){
  var lr = lr_set['lr'];
  if (curr_gen == n_gens+1){
    var genObj = {speaker: speaker, cg_type: 'approx', curr_gen: curr_gen, speaker_beliefs: speaker_beliefs, listener_beliefs: listener_beliefs, 
      cg_speaker: cg_speaker, cg_listener: cg_listener, sampler: sampler, lr: lr_set['name']};
    return genObj;
  } else {
    var world_set = speaker_beliefs['params']['vs'];
    var sampled_w = sample_world(speaker_beliefs,cg_speaker,world_set,sampler);
    if (sampled_w["Index"] == -1){
      var selected_u = "NULL";
      var genObj = {speaker: speaker, cg_type: 'approx', curr_gen: curr_gen, speaker_beliefs: speaker_beliefs, listener_beliefs: listener_beliefs, 
      sampled_w: sampled_w, selected_u: selected_u, cg_speaker: cg_speaker, cg_listener: cg_listener, sampler: sampler, lr: lr_set['name']};
      printGeneration(genObj);
      var next_speaker = (speaker == "a")? "b" : "a";
      return runApproxConversationHelper(next_speaker,curr_gen+1,n_gens,cg_listener,cg_speaker,listener_beliefs,speaker_beliefs,sampler,lr_set);
    } else {
      var selected_u = pick_utterance(sampled_w,cg_speaker);
      var int_posteriors_speaker = interpret_utterance(selected_u,cg_speaker); //speaker assumes listener uses CG to interpret
      var int_posteriors_listener = interpret_utterance_listener(selected_u,cg_listener,listener_beliefs); //listener uses their own beliefs as priors, but assumes speaker uses CG to sample
      var new_cg_speaker = update_cg(cg_speaker,int_posteriors_speaker,lr_set['speaker_cg']);
      var new_cg_listener = update_cg(cg_listener,int_posteriors_listener,lr_set['listener_cg']);
      var belief_lr = (lr_set['listener_belief'] == 'entropyAdjusted') ? adjustLR(listener_beliefs,new_cg_listener) : lr_set['listener_belief'];
      var new_listener_beliefs = update_beliefs(listener_beliefs,int_posteriors_listener,belief_lr);
      var genObj = {speaker: speaker, cg_type: 'approx', curr_gen: curr_gen, speaker_beliefs: speaker_beliefs, listener_beliefs: new_listener_beliefs, 
      sampled_w: sampled_w, selected_u: selected_u, cg_speaker: new_cg_speaker, cg_listener: new_cg_listener, sampler: sampler, lr: lr_set['name']};
      printGeneration(genObj);
      var next_speaker = (speaker == "a")? "b" : "a";
      runApproxConversationHelper(next_speaker,curr_gen+1,n_gens,new_cg_listener,new_cg_speaker,new_listener_beliefs,speaker_beliefs,sampler,lr_set);
    }
  }
}


// RUN CALL

var main = function(){
  // command-line options
  var world_sampler = samplers[process.argv[3]];
  var cg_shared = process.argv[4];
  var belief_update = process.argv[5];
  var n_moves = Math.floor(process.argv[6]);

  //Nancy_none : [10,1,1,1,],[1,1,1,1,]
  // Nancy_Katie : [10,1,1,1,],[1,1,10,1,]
  // Nancy7Katie10_Katie10 : 7,10,1,1,],[1,10,1,1,]
  //Nancy7Katie9_Katie15: [7,1,9,1,],[1,1,15,1,]

  //log format of output
  var initial_dists = init_distributions([10,1,1,1,],[1,1,1,1,],balanced_worlds,cg_shared);
  var a_beliefs = initial_dists['a_beliefs'];
  var b_beliefs = initial_dists['b_beliefs'];
  //var lr_set = {name: 'plain', speaker_cg: 0.2, listener_cg: 0.2, listener_belief: 0.2, lr: 0.2};
  //var lr_set = {name: 'suspicious', speaker_cg: 0.2, listener_cg: 0.1, listener_belief: 0.1, lr: 0.2};
  var lr_set = {name: 'entropy', speaker_cg: 0.2, listener_cg: 0.2, listener_belief: "entropyAdjusted", lr: 0.2};
  if (cg_shared == 'shared'){
    var cg = initial_dists['cg'];
    console.log('speaker,cg,generation,sampler,sampled_w_idx,selected_u,listener_belief,speaker_belief,location_pref,name,school/company,major,w_idx,cg_prob');
    runSharedFixedConversation(n_moves,cg,a_beliefs,b_beliefs,world_sampler,lr_set);
  } else{
    if (cg_shared == 'approx' & belief_update == 'no'){
    var cg_a = initial_dists['cg_a'];
    var cg_b = initial_dists['cg_b'];
    console.log('speaker,cg,generation,sampler,sampled_w_idx,selected_u,listener_belief,speaker_belief,location_pref,name,school/company,major,w_idx,cg_listener_prob,cg_speaker_prob');
    runApproxFixedConversation(n_moves,cg_a,cg_b,a_beliefs,b_beliefs,world_sampler,lr_set);
  } else {
    var cg_a = initial_dists['cg_a'];
    var cg_b = initial_dists['cg_b'];
    console.log('speaker,cg,generation,sampler,sampled_w_idx,selected_u,listener_belief,speaker_belief,location_pref,name,school/company,major,w_idx,cg_listener_prob,cg_speaker_prob');
    runApproxConversation(n_moves,cg_a,cg_b,a_beliefs,b_beliefs,world_sampler,lr_set);
  }
  }
  return
};

// COMMAND LINE ARGS


if(process.argv[5]==undefined){
  console.log('Usage: webppl conversation_update.wppl sampler cg_shared? n_moves');
} else{
  main();
};